from openai import OpenAI
import streamlit as st
import os
from dotenv import load_dotenv
from pypdf import PdfReader


load_dotenv()
api_key = os.getenv("openaikey")
client = OpenAI(api_key=api_key)


st.set_page_config(
    page_title="PDF AI Chatbot",
    page_icon="ğŸ¤–",
    layout="centered"
)

st.header("ğŸ“„PDF Destekli AI Sohbet Botu")
st.divider()


SYSTEM_PROMPTS = {
    "Genel": (
        "Sen TÃ¼rkÃ§e konuÅŸan, yardÄ±msever ve aÃ§Ä±klayÄ±cÄ± bir yapay zeka asistansÄ±n."
    ),
    "Python EÄŸitmeni": (
        "Sen Python konusunda uzman bir eÄŸitmensin. "
        "KodlarÄ± sade ve Ã¶rneklerle anlatÄ±rsÄ±n."
    ),
    ".NET UzmanÄ±": (
        "Sen ASP.NET Core, C# ve backend mimarileri konusunda uzman bir yazÄ±lÄ±mcÄ±sÄ±n. "
        "Clean Code ve best practice kullanÄ±rsÄ±n."
    ),
    "Almanca Ã–ÄŸretmeni": (
        "Sen TELC B2 seviyesinde Almanca Ã¶ÄŸreten bir asistansÄ±n. "
        "Basit ve anlaÅŸÄ±lÄ±r anlatÄ±rsÄ±n."
    )
}


st.sidebar.title("âš™ï¸ Ayarlar")

assistant_role = st.sidebar.selectbox(
    "Asistan RolÃ¼",
    list(SYSTEM_PROMPTS.keys())
)

uploaded_pdf = st.sidebar.file_uploader(
    "ğŸ“„ PDF YÃ¼kle",
    type="pdf"
)


if "current_role" not in st.session_state:
    st.session_state.current_role = assistant_role

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": SYSTEM_PROMPTS[assistant_role]}
    ]

if "pdf_text" not in st.session_state:
    st.session_state.pdf_text = ""


if st.session_state.current_role != assistant_role:
    st.session_state.messages = [
        {"role": "system", "content": SYSTEM_PROMPTS[assistant_role]}
    ]
    st.session_state.current_role = assistant_role
    st.session_state.pdf_text = ""


if st.sidebar.button("ğŸ§¹ Sohbeti Temizle"):
    st.session_state.messages = [
        {"role": "system", "content": SYSTEM_PROMPTS[assistant_role]}
    ]
    st.session_state.pdf_text = ""
    st.rerun()


def extract_pdf_text(pdf_file) -> str:
    reader = PdfReader(pdf_file)
    text = ""
    for page in reader.pages:
        extracted = page.extract_text()
        if extracted:
            text += extracted + "\n"
    return text[:12000]  # token kontrolÃ¼

if uploaded_pdf:
    st.session_state.pdf_text = extract_pdf_text(uploaded_pdf)
    st.sidebar.success("âœ… PDF baÅŸarÄ±yla yÃ¼klendi")


MAX_MESSAGES = 12

def trim_messages():
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = (
            [st.session_state.messages[0]] +
            st.session_state.messages[-MAX_MESSAGES:]
        )


def generate_response(prompt: str) -> str:
    try:
        if st.session_state.pdf_text:
            user_prompt = f"""
AÅŸaÄŸÄ±daki PDF iÃ§eriÄŸine gÃ¶re soruyu cevapla.
EÄŸer cevap PDF iÃ§inde yoksa bunu aÃ§Ä±kÃ§a belirt.

PDF Ä°Ã‡ERÄ°ÄÄ°:
{st.session_state.pdf_text}

SORU:
{prompt}
"""
        else:
            user_prompt = prompt

        st.session_state.messages.append(
            {"role": "user", "content": user_prompt}
        )

        trim_messages()

        response = client.responses.create(
            model="gpt-4.1-mini",
            input=st.session_state.messages
        )

        return response.output_text

    except Exception as e:
        return f"âŒ Bir hata oluÅŸtu: {str(e)}"


for message in st.session_state.messages[1:]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


if prompt := st.chat_input("PDF hakkÄ±nda bir soru sor veya mesaj yaz..."):
    st.chat_message("user").markdown(prompt)

    with st.spinner("Asistan dÃ¼ÅŸÃ¼nÃ¼yor... ğŸ¤–"):
        response = generate_response(prompt)

    with st.chat_message("assistant"):
        st.markdown(response)

    st.session_state.messages.append(
        {"role": "assistant", "content": response}
    )
